{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks <img src=\"reports/icon_rna.svg\"  align=\"center\" height=auto width=10%/>\n",
    "_Multilayer perceptron (MLP)_\n",
    "\n",
    "## Summary\n",
    "  - [Neural Networks Definition](#neural-networks-definition)\n",
    "   - [Modeling](#modeling)\n",
    "   - [Mathematical](#mathematical)\n",
    "   - [Space Probability](#space-probability)\n",
    "   - [Adding Weights to Models](#adding-weights-to-models)\n",
    "  - [Deep Learning Definition](#deep-learning-definition)\n",
    "  - [Advantages](#advantages)\n",
    "  - [Disadvantages](#disadvantages)\n",
    "  - [Machine Learnig X Deep Learning](#machine-learnig-X-deep-learning)\n",
    "  - [Creating Neural Networks](#)\n",
    "    - [Adding Weights to Models](#)\n",
    "  - [Math](#math)\n",
    "  - [Architecture](#architecture)\n",
    "    - [Representation of a Linear Model in a Neural Network](#representation-of-a-linear-model-in-a-neural-network)\n",
    "  - [Deep Architectures](#deep-architectures)\n",
    "  - [Activate Function](#activate-function)\n",
    "  - [Mathematic Model](#mathematic-model) \n",
    "  - [Deep Learning Frameworks](#deep-learning-frameworks) \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6234676712de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Neural Networks Definition**\n",
    "Neural network são uma sequência de modelos lineares e funções de ativação.\n",
    "\n",
    "### Modeling\n",
    "Dado 2 modelos lineares\n",
    "\n",
    "<img src=\"reports/two_models.png\"  align=\"center\" height=auto width=20%/>\n",
    "\n",
    "É possível conecta-los e criar modelos não lineares\n",
    "\n",
    "<img src=\"reports/2perceptrons.png\"  align=\"center\" height=auto width=75%/>\n",
    "<br/>\n",
    "\n",
    "### Mathematical\n",
    "A fórmula básica do modelo fica como:\n",
    "\n",
    "$$\\hat{^y} = \\sigma(w_1 x_1)\\ * \\sigma(w_2 x_2) \\ $$\n",
    "\n",
    "O que acontece matematicamente é um **achatamento (flatten) da matriz de dados da layer anterior** para alimentar a layer seguinte.\n",
    "<br/>\n",
    "\n",
    "#### Space Probability\n",
    "Um modelo linear cria um espaço de probabilidade, onde cada ponto retorna um valor probabilístico de ser azul ou vermelho.\n",
    "\n",
    "<img src=\"reports/add_perceptrons.png\"  align=\"center\" height=auto width=70%/>\n",
    "\n",
    "A soma das probabilidades de cada ponto dá > 1, mas por ser um espaço amostral, o retorno precisa estar entre 0 e 1. Para isso é utilizado um função de ativação.\n",
    "\n",
    "<img src=\"reports/perceptrons_sigmoid.png\" align=\"center\" height=auto width=90%/>\n",
    "<br/>\n",
    "\n",
    "#### Adding Weights to Models\n",
    "É através dos pesos (**w**) do modelo que uma neural network pode ser enviezada.\n",
    "\n",
    "<img src=\"reports/combining_perceptrons_sigmoind.png\" align=\"center\" height=auto width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Deep Learning Definition**\n",
    "\n",
    "Deep Learning é um método de aprendizado estatístico que extrai features de dados brutos e constrói representações dos dados automaticamente.\n",
    "\n",
    "### **Universal Approximation Theorem**\n",
    "Deep learning pode ser definido como uma técnica que segue o teorema de **Universal Approximation**. Este teorema afirma que:\n",
    "\n",
    "#### **Com uma única layer hidden tendo neurônios finitos, é possível aproximar qualquer função contínua.**\n",
    "\n",
    "### Proof\n",
    "Para demonstrar a prova, abaixo há um função de grau n onde não sabemos qual é a equação.\n",
    "\n",
    "<img src=\"reports/proof-1.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "Para resolver esse problema, dividirei essa função em várias partes menores para que cada parte seja representada por uma função mais simples.\n",
    "\n",
    "<img src=\"reports/proof-2.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "O ponto-chave a ser observado nesse caso é que não preciso me preocupar em apresentar equações complexas para representar a relação entre entrada e saída. Posso apenas criar uma função simples e usar a combinação dessas funções para aproximar o relacionamento do meu verdadeiro relacionamento. Quanto mais funções eu escolher neste método, melhor será a minha aproximação.\n",
    "\n",
    "<img src=\"reports/proof-3.png\" align=\"center\" height=auto width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Visualize Perceptrons by Layer**\n",
    "No exemplo abaixo será modelado a função `y = x*sin(x)` usando uma neural network.\n",
    "Assuma que a neural network está usando funções de ativação ReLU.\n",
    "\n",
    "### One Perceptron\n",
    "Uma neural network com uma única layer hidden dá **apenas um grau de liberdade** para brincar. Portanto, acabamos com uma aproximação muito ruim da função.\n",
    "\n",
    "<img src=\"reports/one_node.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "### Two Perceptron\n",
    "\n",
    "<img src=\"reports/two_node.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "### Three Perceptrons\n",
    "\n",
    "<img src=\"reports/three_node.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "### N Perceptrons\n",
    "\n",
    "<img src=\"reports/n_nodes.png\" align=\"center\" height=auto width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Machine Learning X Deep Learning**\n",
    "A imagem abaixo compara os tipos de resolução de problemas.\n",
    "\n",
    "<img src=\"reports/ml_classic_deep.png\" align=\"center\" height=auto width=60%/>\n",
    "\n",
    "### Data Size\n",
    "Os métodos de machine learning fazem muito mais sentido com pequenos datasets. Por exemplo, se você tiver apenas 100 pontos de dados, árvores de decisão, vizinhos mais próximos k e outros modelos de aprendizado de máquina serão muito mais valiosos para você do que ajustar uma neural network profunda nos dados.\n",
    "\n",
    "<img src=\"reports/Effect-of-training-data-size-on-deep-learning-performance.ppm\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "\n",
    "### Feature Extractition\n",
    "O processo de feature importance é algo que demanda conhecimento sobre o domínio do problema. Já na etapa seguinte, de feature extraction, leva em conta as features com mais influência no resultado.\n",
    "\n",
    "<img src=\"reports/feature_extractition.png\" align=\"center\" height=auto width=80%/>\n",
    "\n",
    "Deep Learning faz o processo de feature extraction\n",
    "\n",
    "\n",
    "### Interpretability \n",
    "Modelos baseados em neural networks são os que apresentam a maior accuracy. Porém, apresentam alta complexidade o que torna difícil de intepretar os resultado (black box).\n",
    "\n",
    "<img src=\"reports/model_interpretability.png\" align=\"center\" height=auto width=60%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Advantages**\n",
    "- As neural networks artificiais (RNAs) são utilizadas para aprender sobre features representativas de modo automatizado.\n",
    "- Elas são extremamente simples, uma vez que tenhamos entendido os modelos lineares.\n",
    "- São bastante intuitivas, pois permitem a interpretação de aprendizado de níveis de abstrações hierárquicos.\n",
    "- São muito flexíveis, o que as torna ideais para resolver os mais diversos tipos de problemas.\n",
    "- São absurdamente efetivas quanto a qualidade dos resultados.\n",
    "- Com um conjunto grande de neurônios, é possível produzir funções contínuas de complexidade arbitrária.\n",
    "\n",
    "## **Disadvantages**\n",
    "- Modelos gigantescos, consumindo recurso computacional.\n",
    "- treinar uma RNA é extremamente difícil, dado o formato não convexo da função custo. \n",
    "- Fácil de ter overfit\n",
    "- Só vale a pena para muitos dados > 100.000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Types of layer**\n",
    "Neural network possuem uma arquitetura em layers que são:\n",
    "- input\n",
    "- hidden\n",
    "- output\n",
    "\n",
    "<img src=\"reports/layer.png\" align=\"center\" height=auto width=60%/>\n",
    "\n",
    "Quando conectamos essas duas redes, obtemos uma rede com maior flexibilidade devido ao aumento do número de graus de liberdade.\n",
    "\n",
    "As layers podem ser:\n",
    "- densas (totalmente conectadas)\n",
    "- covulacionais: `Conv1D`, `Conv2D` e `Conv3D`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Dense Layer\n",
    "- **É quando todas as layers de inputs são conectadas em todos as layers de outputs**. \n",
    "- É a arquitetura mais simples em deep learning\n",
    "- Se a layer de input possuir mais de um perceptron os dados precisam ser achatados (flatten).\n",
    "- Em cada conexão há um peso (**w**)\n",
    "- Um problema de layer densas é que o consumo de memória é linear \n",
    "\n",
    "<img src=\"reports/dense_layer_pa3.png\" align=\"center\" height=auto width=50%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-bbcfe6d57c41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'keras' is not defined"
     ]
    }
   ],
   "source": [
    "keras.layers.Dense(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-d2e6badb56b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "tf.keras.layers.Dense(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**units:** integer, dimensionalidade de saída,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covulational Layer\n",
    "Usa filtros de avaliação dos pesos \n",
    "\n",
    "<img src=\"reports/convolution-layer-a.gif\" align=\"center\" height=auto width=40%/>\n",
    "\n",
    "### Logits\n",
    "- Logits é o logaritmo das probabilidades\n",
    "- o termo layer de logits é usado para a última layer de perceptrons de uma neural network para tarefas de classificação que produz valores de previsão.\n",
    "- Exemplo de logits: softmax\n",
    "\n",
    "### Simple Layers\n",
    "São layers que podem ser inseridas nas neural networks mas não são perceptrons completos.\n",
    "- Activation\n",
    "- Dropout\n",
    "- Regularization\n",
    "- Flatten\n",
    "- Embedding\n",
    "\n",
    "#### Flatten\n",
    "<img src=\"reports/flatten.png\" align=\"center\" height=auto width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Neural Networks Architectures**\n",
    "\n",
    "<img src=\"reports/linear_perceptrons.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "O **bias pode ser representado como um nodo da rede** ou sendo como o valor resultante de nodos.\n",
    "\n",
    "<img src=\"reports/join_models.png\" align=\"center\" height=auto width=70%/>\n",
    "\n",
    "Junção de nodos e adição do nodo de ativação\n",
    "\n",
    "<img src=\"reports/neural_network.png\" align=\"center\" height=auto width=40%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Deep Neural Networks Architectures**\n",
    "A partir do momento que se tem muitas hidden layers já é um deep neural network\n",
    "\n",
    "<br/>\n",
    "<img src=\"reports/simple_x_deep.png\" align=\"center\" height=auto width=80%/>\n",
    "<br/>\n",
    "\n",
    "#### Example\n",
    "<img src=\"reports/deep_nw.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "**+**\n",
    "\n",
    "<img src=\"reports/multilayer.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "**+**\n",
    "...\n",
    "\n",
    "**=**\n",
    "\n",
    "$$\\hat{^y} = \\sigma(w_1 x_1)\\ * \\sigma(w_2 x_2) \\ *...* \\sigma(w_n x_n) \\ + bias $$\n",
    "\n",
    "\n",
    "<img src=\"reports/deep_neural_networks.png\" align=\"center\" height=auto width=70%/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Good Pratices\n",
    "**É uma boa prática usar várias layers hiddens, bem como vários nós nas layers hiddens, pois elas parecem resultar no melhor desempenho.**\n",
    "\n",
    "<img src=\"reports/goodfellow.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "Foi demonstrado por Ian Goodfellow (o criador da rede contraditória generativa) que aumentar o número de layers de neural networks tende a melhorar a precisão geral do conjunto de testes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/?hl=pt_br#activation=tanh&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=6,2&seed=0.76476&showTestData=false&discretize=true&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Mathematic Model**\n",
    "\n",
    "**Neural networks são aninhamentos sucessivos de diversas transformações lineares seguidas por alguma função de ativação**, que é aplicada elemento a elemento da matriz de entrada.\n",
    "\n",
    "Hypothesis\n",
    "\\begin{align*}\n",
    "H(x) = Wx + b\n",
    "\\end{align*}\n",
    "\n",
    "Cost function\n",
    "\\begin{align*}\n",
    "cost(W,b) = \\frac{1}{m} \\sum_{i=1}^m (H(x_i) - y_i)^ 2\n",
    "\\end{align*}\n",
    "\n",
    "Gradient descent\n",
    "\\begin{align*}\n",
    "W_new = W - \\alpha {\\frac{1}{m} \\sum_{i=1}^m ((W * x_{i}) - y_{i}) * x_i}\n",
    "\\end{align*}\n",
    "\n",
    "<img src=\"reports/matriz_neural_network.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "- a matriz **W** é a layer hidden da neural network e cada coluna dessa matriz é um neurônio\n",
    "- o vetor **w** é o bias\n",
    "- **x** layer de input\n",
    "- **y** layer de output\n",
    "\n",
    "#### Resume Formulas\n",
    "\n",
    "<img src=\"reports/resume_formula.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "<img src=\"reports/chain_rule.png\" align=\"center\" height=auto width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Neural Networks Steps** \n",
    "\n",
    "<img src=\"reports/ppipeline_neraul_netowork.png\" align=\"rightr\" height=auto width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Deep Learning Frameworks**\n",
    "\n",
    "<img src=\"reports/frameworks.png\"  align=\"center\" height=auto width=90%/>\n",
    "\n",
    "- Tutorias das documentações de:\n",
    "  - tensorFlow\n",
    "  - pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0-dev20191002'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Binary Class https://kunicom.blogspot.com/2017/06/09-binary-classification.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation <img src=\"reports/keras-logo-small.jpg\" align=\"center\" height=auto width=10%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize Architecture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly-2.0-preview\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/be/e4e2cc0b4896648fe6d5e45dda6d8c3b784823301708cfe4ff96de9e01cf/tf_nightly_2.0_preview-2.0.0.dev20191002-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Collecting tb-nightly<2.2.0a0,>=2.1.0a0\n",
      "  Downloading https://files.pythonhosted.org/packages/48/6b/b9e735120c77721570aed36cec55390827db0d580b14a5ffd93a4cce5997/tb_nightly-2.1.0a20191206-py3-none-any.whl (3.8MB)\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting tensorflow-estimator-2.0-preview\n",
      "  Using cached https://files.pythonhosted.org/packages/db/f5/790508e193121ab301cb40cada7f451c531404051ac9249f21b1f5484450/tensorflow_estimator_2.0_preview-2.0.0-py2.py3-none-any.whl\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp36-none-any.whl\n",
      "Collecting protobuf>=3.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/b8/be/438a8b90701aacfd7d741541571a236edbcf46f772caa25fcb27c4937e9e/protobuf-3.11.1-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n",
      "Processing /home/campos/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp36-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833/opt_einsum-3.1.0-cp36-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd/wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting six>=1.10.0\n",
      "  Using cached https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Using cached https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached https://files.pythonhosted.org/packages/27/28/280658104af767431cf25e397157c4f4a8724a446f9dd5a34dac9812e9c9/grpcio-1.25.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc/absl_py-0.8.1-cp36-none-any.whl\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Downloading https://files.pythonhosted.org/packages/ec/11/1d90cbfa72a084b08498e8cea1fee199bc965cdac391d241f5ae6257073e/google_auth-1.7.2-py2.py3-none-any.whl (74kB)\n",
      "Collecting setuptools>=41.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl\n",
      "Collecting h5py\n",
      "  Using cached https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting cachetools<3.2,>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: astor, werkzeug, setuptools, markdown, pyasn1, pyasn1-modules, rsa, six, cachetools, google-auth, certifi, chardet, idna, urllib3, requests, oauthlib, requests-oauthlib, google-auth-oauthlib, protobuf, grpcio, numpy, absl-py, wheel, tb-nightly, tensorflow-estimator-2.0-preview, google-pasta, gast, termcolor, opt-einsum, wrapt, h5py, keras-applications, keras-preprocessing, tf-nightly-2.0-preview\n",
      "  Found existing installation: astor 0.8.0\n",
      "    Uninstalling astor-0.8.0:\n",
      "      Successfully uninstalled astor-0.8.0\n",
      "  Found existing installation: Werkzeug 0.16.0\n",
      "    Uninstalling Werkzeug-0.16.0:\n",
      "      Successfully uninstalled Werkzeug-0.16.0\n",
      "  Found existing installation: setuptools 42.0.2\n",
      "    Uninstalling setuptools-42.0.2:\n",
      "      Successfully uninstalled setuptools-42.0.2\n",
      "  Found existing installation: Markdown 3.1.1\n",
      "    Uninstalling Markdown-3.1.1:\n",
      "      Successfully uninstalled Markdown-3.1.1\n",
      "  Found existing installation: pyasn1 0.4.8\n",
      "    Uninstalling pyasn1-0.4.8:\n",
      "      Successfully uninstalled pyasn1-0.4.8\n",
      "  Found existing installation: pyasn1-modules 0.2.7\n",
      "    Uninstalling pyasn1-modules-0.2.7:\n",
      "      Successfully uninstalled pyasn1-modules-0.2.7\n",
      "  Found existing installation: rsa 4.0\n",
      "    Uninstalling rsa-4.0:\n",
      "      Successfully uninstalled rsa-4.0\n",
      "  Found existing installation: six 1.13.0\n",
      "    Uninstalling six-1.13.0:\n",
      "      Successfully uninstalled six-1.13.0\n",
      "  Found existing installation: cachetools 3.1.1\n",
      "    Uninstalling cachetools-3.1.1:\n",
      "      Successfully uninstalled cachetools-3.1.1\n",
      "  Found existing installation: google-auth 1.7.1\n",
      "    Uninstalling google-auth-1.7.1:\n",
      "      Successfully uninstalled google-auth-1.7.1\n",
      "  Found existing installation: certifi 2019.11.28\n",
      "    Uninstalling certifi-2019.11.28:\n",
      "      Successfully uninstalled certifi-2019.11.28\n",
      "  Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Found existing installation: idna 2.8\n",
      "    Uninstalling idna-2.8:\n",
      "      Successfully uninstalled idna-2.8\n",
      "  Found existing installation: urllib3 1.25.7\n",
      "    Uninstalling urllib3-1.25.7:\n",
      "      Successfully uninstalled urllib3-1.25.7\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: oauthlib 3.1.0\n",
      "    Uninstalling oauthlib-3.1.0:\n",
      "      Successfully uninstalled oauthlib-3.1.0\n",
      "  Found existing installation: requests-oauthlib 1.3.0\n",
      "    Uninstalling requests-oauthlib-1.3.0:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.0\n",
      "  Found existing installation: google-auth-oauthlib 0.4.1\n",
      "    Uninstalling google-auth-oauthlib-0.4.1:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.1\n",
      "  Found existing installation: protobuf 3.11.0\n",
      "    Uninstalling protobuf-3.11.0:\n",
      "      Successfully uninstalled protobuf-3.11.0\n",
      "  Found existing installation: grpcio 1.25.0\n",
      "    Uninstalling grpcio-1.25.0:\n",
      "      Successfully uninstalled grpcio-1.25.0\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "  Found existing installation: absl-py 0.8.1\n",
      "    Uninstalling absl-py-0.8.1:\n",
      "      Successfully uninstalled absl-py-0.8.1\n",
      "  Found existing installation: wheel 0.33.6\n",
      "    Uninstalling wheel-0.33.6:\n",
      "      Successfully uninstalled wheel-0.33.6\n",
      "  Found existing installation: tb-nightly 2.1.0a20191201\n",
      "    Uninstalling tb-nightly-2.1.0a20191201:\n",
      "      Successfully uninstalled tb-nightly-2.1.0a20191201\n",
      "  Found existing installation: google-pasta 0.1.8\n",
      "    Uninstalling google-pasta-0.1.8:\n",
      "      Successfully uninstalled google-pasta-0.1.8\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Found existing installation: opt-einsum 3.1.0\n",
      "    Uninstalling opt-einsum-3.1.0:\n",
      "      Successfully uninstalled opt-einsum-3.1.0\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Found existing installation: Keras-Applications 1.0.8\n",
      "    Uninstalling Keras-Applications-1.0.8:\n",
      "      Successfully uninstalled Keras-Applications-1.0.8\n",
      "  Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Found existing installation: tf-nightly-2.0-preview 2.0.0.dev20191002\n",
      "    Uninstalling tf-nightly-2.0-preview-2.0.0.dev20191002:\n",
      "      Successfully uninstalled tf-nightly-2.0-preview-2.0.0.dev20191002\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 certifi-2019.11.28 chardet-3.0.4 gast-0.2.2 google-auth-1.7.2 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.8 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.17.4 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.1 pyasn1-0.4.8 pyasn1-modules-0.2.7 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0 setuptools-42.0.2 six-1.13.0 tb-nightly-2.1.0a20191206 tensorflow-estimator-2.0-preview-2.0.0 termcolor-1.1.0 tf-nightly-2.0-preview-2.0.0.dev20191002 urllib3-1.25.7 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorboard as it is not installed.\n",
      "ERROR: tensorflow 2.0.0 requires tensorboard<2.1.0,>=2.0.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip3 uninstall tensorboard -y\n",
    "pip3 install --force-reinstall tf-nightly-2.0-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n",
      "tb-nightly                        2.1.0a20191206   \n"
     ]
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ \n",
    "\n",
    "!python3 -m pip list | grep tb\n",
    "# tb-nightly           1.15.0a20190806"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "60000/60000 [==============================] - 2s 29us/step - loss: 0.6976 - accuracy: 0.7579\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7ff95c666fd0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model.\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "(train_images, train_labels), _ = keras.datasets.fashion_mnist.load_data()\n",
    "train_images = train_images / 255.0\n",
    "\n",
    "# Define the Keras TensorBoard callback.\n",
    "logdir=\"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "# Train the model.\n",
    "model.fit(\n",
    "    train_images,\n",
    "    train_labels, \n",
    "    batch_size=64,\n",
    "    epochs=1, \n",
    "    callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-16eba7ad515fdacb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-16eba7ad515fdacb\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install keras\n",
    "# !pip3 install pydot\n",
    "# !pip3 install pydotplus\n",
    "# !pip3 install graphviz\n",
    "# !sudo apt install graphviz -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para criar neural network no Keras é necessário seguir estes passos:\n",
    "\n",
    "<img src=\"reports/keras_processing.png\" align=\"center\" height=auto width=20%/>   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 2)\n",
      "(4, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pydot\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.layers import Layer\n",
    "\n",
    "from keras.utils import plot_model\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "\n",
    "\n",
    "# X tem formato (num_rows, num_cols), onde os dados de treinamento são armazenados\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=np.float32)\n",
    "\n",
    "# y deve conter um vetor de saída para cada vetor de entrada\n",
    "y = np.array([[0], [0], [0], [1]], dtype=np.float32)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.engine.sequential.Sequential at 0x7f90445d6390>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sequential model\n",
    "model = Sequential()\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct Neural Network Architecture\n",
    "O keras exige que seja especificado na primeira layer o formato dos tensores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Input Layer**\n",
    "Uma layer de entrada de 32 nodos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = Dense(units=32, input_dim=X.shape[1])\n",
    "\n",
    "model.add(input_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hidden Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Output Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_layer = Activation('sigmoid')\n",
    "\n",
    "model.add(output_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Model\n",
    "\n",
    "Quando invocado a função `model.save()` é salvado as seguintes informações:\n",
    "- arquitetura da neural network\n",
    "- weights\n",
    "- configuração do treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model_path = \"/tmp/predict_student_admissions.pkl\"\n",
    "model.save(keras_model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loss Function and Optimizer\n",
    "- O modelo precisa de uma função loss e um otimizador (optimizer) para treinamento.\n",
    "- Quando tivermos construído nosso modelo, temos que compilá-lo antes que seja executado. Compilar um modelo do Keras chama o backend (tensorflow, theano, etc.)\n",
    "\n",
    "`compile()` tem 3 argumentos:\n",
    "\n",
    "* `optimizer`: This object specifies the training procedure.\n",
    "* `loss`: The function to minimize during optimization. \n",
    "* `metrics`: Used to monitor training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd',\n",
    "              loss='mse',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best Practices\n",
    "\n",
    "- Gerar um `summary()`\n",
    "- Gerar um `plt_model()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keras.utils.vis_utils.pydot = pydot\n",
    "# plot_model(model, to_file='reports/model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainning\n",
    "\n",
    "`fit()` precisa de 3 argumentos:\n",
    "\n",
    "* `epochs`: Training is structured into *epochs*. \n",
    "* `batch_size`: When passed NumPy data, the model slices the data into **smaller batches**\n",
    "* `validation_data`: When prototyping a model, you want to easily monitor its\n",
    "  performance on some validation data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X, y, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Trainning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = model.evaluate(X, y, verbose=1)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Refereces\n",
    "\n",
    "- [1] https://matheusfacure.github.io/2017/03/05/ann-intro/\n",
    "- [2] https://youtu.be/Boy3zHVrWB4\n",
    "- [3] https://www.youtube.com/watch?v=DGNbd2FGw2s\n",
    "- [4] https://matheusfacure.github.io/2017/07/12/activ-func/\n",
    "- [5] https://towardsdatascience.com/comprehensive-introduction-to-neural-network-architecture-c08c6d8e5d98\n",
    "- [6] https://stanford.edu/~shervine/teaching/cs-230/cheatsheet-deep-learning-tips-and-tricks\n",
    "- [7] https://medium.com/themlblog/getting-started-with-tensorflow-constants-variables-placeholders-and-sessions-80900727b489\n",
    "- [8] https://en.wikipedia.org/wiki/Universal_approximation_theorem\n",
    "- [9] https://www.iangoodfellow.com/slides/learn_ai_with_the_best.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
