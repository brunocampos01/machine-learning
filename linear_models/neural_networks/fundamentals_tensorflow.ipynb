{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fundamentals <img src=\"reports/tensorflow.svg\"  align=\"center\" height=auto width=30%/>\n",
    "_I would describe tensorflow as a open source machine learning framework developed by Google which can be used to build neural networks._\n",
    "\n",
    "## Summary\n",
    "  - [Advantages](#advantages)\n",
    "  - [Disadvantages](#disadvantages)\n",
    "  - [Machine Learnig X Deep Learning](#machine-learnig-X-deep-learning)\n",
    "  - [Creating Neural Networks](#)\n",
    "    - [Adding Weights to Models](#)\n",
    "  - [Math](#math)\n",
    "  - [Architecture](#architecture)\n",
    "    - [Representation of a Linear Model in a Neural Network](#representation-of-a-linear-model-in-a-neural-network)\n",
    "  - [Deep Architectures](#deep-architectures)\n",
    "  - [Activate Function](#activate-function)\n",
    "  - [Mathematic Model](#mathematic-model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to work\n",
    "Tensorflow trabalha com grafos de dados onde cada nodo são operações matemáticas e as arestas são os dados em estruturas de tensores.\n",
    "\n",
    "<img src=\"reports/nodes.gif\" align=\"rightr\" height=auto width=30%/>\n",
    "\n",
    "<img src=\"reports/flow_data_tf.gif\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "\n",
    "#### Tensors\n",
    "\n",
    "| Rank | Math entity                      | Python example                          |\n",
    "|------|----------------------------------|-----------------------------------------|\n",
    "| 0    | Scalar (magnitude only)          | s = 100                                 |\n",
    "| 1    | Vector (magnitude and direction) | v = [1,2,3]                             |\n",
    "| 2    | Matrix (table of numbers)        | m = [[1,2,3], [1,2,3]]                  |\n",
    "| 3    | 3-Tensor (cube of numbers)       | t = [[[2], [4], [6]], [[8], [9], [10]]] |\n",
    "\n",
    "#### Tensor Shape\n",
    "| Rank | Shape        | Dimension number | Example                         |\n",
    "|------|--------------|------------------|---------------------------------|\n",
    "| 0    | []           | 0-D              | A 0-D tensor. A Scalar          |\n",
    "| 1    | [D0]         | 1-D              | A 1-D tensor with shape [5]     |\n",
    "| 2    | [D0, D1]     | 2-D              | A 2-D tensor with shape [3, 4]  |\n",
    "| 3    | [D0, D1, D2] | 3-D              | A 3-D tensor with shape [1,4,3] |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Type Data\n",
    "- Placeholder: é um **espaço reservado** para ser usado por um tensor\n",
    "- Variáveis\n",
    "- Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1. 2. 3. 4.], shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Creates a constant node\n",
    "x = tf.constant(value=[1,2,3,4],\n",
    "                dtype='float32',\n",
    "                shape=None,\n",
    "                name='Const')\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'var:0' shape=(4,) dtype=float32, numpy=array([6., 7., 8., 9.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "var = tf.Variable(x + 5, \n",
    "                  name='var',\n",
    "                 dtype='float32')\n",
    "\n",
    "print(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Placeholder_7:0\", shape=(4,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "placeholder = tf.keras.backend.placeholder(4, dtype='float32')\n",
    "print(placeholder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playground Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://playground.tensorflow.org/?hl=pt_br#activation=tanh&batchSize=10&dataset=xor&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=6,2&seed=0.76476&showTestData=false&discretize=true&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running a Graph\n",
    "Para executar um objeto do tipo grafo (tensorflow) execute:\n",
    "```python\n",
    "tf.Session\n",
    "```\n",
    "\n",
    "o objeto do tipo grafo será encapsulado\n",
    "\n",
    "#### Why do need a session object?\n",
    "- DEPRECATED, tensorflow 2.0\n",
    "- Python pode executar objeto do tipo grafo ou tensores porém **Python é muito lento**. Ao invocar uma `session()` garantimos que as operações serão executadas em C++\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a constant node\n",
    "x = tf.constant([1,2,3,4,5])\n",
    "y = tf.constant([6,7,8,9,10])\n",
    "\n",
    "result = tf.multiply(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 6 14 24 36 50], shape=(5,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computation Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "node1: tf.Tensor(3.0, shape=(), dtype=float32)\n",
      "node2: tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "node3: tf.Tensor(7.0, shape=(), dtype=float32)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fc90e5933cb6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# To get outputs of each nodes, session should run the data flow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Session can run single node or list of nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Defines constant and operation nodes\n",
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # tf.float32 can be implicitly given.\n",
    "node3 = tf.add(node1, node2)\n",
    "\n",
    "# If node is printed, only type information will be displayed\n",
    "print(\"node1:\", node1)\n",
    "print(\"node2:\", node2)\n",
    "print(\"node3:\", node3)\n",
    "\n",
    "# To get outputs of each nodes, session should run the data flow graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Session can run single node or list of nodes\n",
    "print(\"sess.run(node1, node2): \", sess.run([node1, node2]))\n",
    "print(\"sess.run(node3): \", sess.run(node3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Mechanics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Build graph using TensoFlow operations\n",
    " - define nodes\n",
    "\n",
    "\n",
    "2. Feed data and run grap (operation)\n",
    " - `sess.run(node)`\n",
    "    \n",
    "    \n",
    "3. Update variables in the graph and return values\n",
    " - `print(output of sess.run(node))`\n",
    " \n",
    "<img src=\"reports/ternsorflow-mecha.png\" align=\"center\" height=auto width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Linear Regression with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'random_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-89722e5f6a40>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Variable is trainable variable for tensorflow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# It will be upated automatically by tensorflow.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'weight'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bias'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'random_normal'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# y = x\n",
    "x_train = [1,2,3]\n",
    "y_train = [1,2,3]\n",
    "\n",
    "# Variable is trainable variable for tensorflow.\n",
    "# It will be upated automatically by tensorflow.\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "\n",
    "print(W)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'W' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-0fe098264d2a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhypothesis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'W' is not defined"
     ]
    }
   ],
   "source": [
    "hypothesis = x_train * W + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost/Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hypothesis' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-af9696f64d93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# reduce_mean calculates average.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhypothesis\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'hypothesis' is not defined"
     ]
    }
   ],
   "source": [
    "# reduce_mean calculates average.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow_core._api.v2.train' has no attribute 'GradientDescentOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a67c48fab700>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training system\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow_core._api.v2.train' has no attribute 'GradientDescentOptimizer'"
     ]
    }
   ],
   "source": [
    "# Training system\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'Session'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-ddf41b25530b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Launch the graph in a session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Initialize global variables in the grpah.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'Session'"
     ]
    }
   ],
   "source": [
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "\n",
    "# Initialize global variables in the grpah.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# For graph\n",
    "steps = []\n",
    "outputs = {\"cost\" : [], \"weight\" : [], \"bias\" : []}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a01b8094648d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0m_cost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0m_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "for step in range(1001):\n",
    "    sess.run(train)\n",
    "\n",
    "    _cost = sess.run(cost)\n",
    "    _weight = sess.run(W)\n",
    "    _bias = sess.run(b)\n",
    "\n",
    "    steps.append(step)\n",
    "    outputs[\"cost\"].append(_cost)\n",
    "    outputs[\"weight\"].append(_weight[0])\n",
    "    outputs[\"bias\"].append(_bias[0])\n",
    "\n",
    "    if step in (1, 10, 100, 1000):\n",
    "        print(\"Step: {0:4d}, Cost: {1:13.10f}, Weight: {2:13.10f}, Bias: {3:13.10f}\".\\\n",
    "              format(step, _cost, _weight[0], _bias[0]))\n",
    "\n",
    "# Draw graph\n",
    "for k, v in outputs.items():\n",
    "    plt.plot(steps, v)\n",
    "    plt.title(k)\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression with Placeholder in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'placeholder'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-a5c98b567cef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Placeholder can be used as input data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# [None] means it is 1 deimensional tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'placeholder'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Placeholder can be used as input data\n",
    "X = tf.placeholder(tf.float32, shape=[None])\n",
    "Y = tf.placeholder(tf.float32, shape=[None])\n",
    "# [None] means it is 1 deimensional tensor\n",
    "#  and its number of values is not determined.\n",
    "\n",
    "# Variable is trainable variable for tensorflow.\n",
    "# It will be upated automatically by tensorflow.\n",
    "W = tf.Variable(tf.random_normal([1]), name='weight')\n",
    "b = tf.Variable(tf.random_normal([1]), name='bias')\n",
    "# [1] means its rank is 1, and its total count is 1.\n",
    "\n",
    "# Hypothesis: W * x + b\n",
    "hypothesis = X * W + b\n",
    "\n",
    "# reduce_mean calculates average.\n",
    "cost = tf.reduce_mean(tf.square(hypothesis - Y))\n",
    "\n",
    "# Training system\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "train = optimizer.minimize(cost)\n",
    "\n",
    "#Until this, we build graph.\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initialize global variables in the grpah.\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# For graph\n",
    "steps = []\n",
    "outputs = {\"cost\" : [], \"weight\" : [], \"bias\" : []}\n",
    "\n",
    "# Train\n",
    "for step in range(1001):\n",
    "    # Return order is the same as the input order of run\n",
    "    _cost, _weight, _bias, _ = sess.run([cost, W, b, train],\\\n",
    "                                        feed_dict={X:[1,2,3], Y:[1,2,3]})\n",
    "\n",
    "    steps.append(step)\n",
    "    outputs[\"cost\"].append(_cost)\n",
    "    outputs[\"weight\"].append(_weight[0])\n",
    "    outputs[\"bias\"].append(_bias[0])\n",
    "\n",
    "    if step in (1, 10, 100, 1000):\n",
    "        print(\\\n",
    "            \"Step: {0:4d}, Cost: {1:13.10f}, Weight: {2:13.10f}, Bias: {3:13.10f}\".\\\n",
    "              format(step, _cost, _weight[0], _bias[0]))\n",
    "\n",
    "# After training, we can test hypothesis with new input\n",
    "print(sess.run(hypothesis, feed_dict={X:[5]}))\n",
    "print(sess.run(hypothesis, feed_dict={X:[1.8, 3.2]}))\n",
    "\n",
    "# Draw graph\n",
    "for k, v in outputs.items():\n",
    "    plt.plot(steps, v)\n",
    "    plt.title(k)\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Traning\n",
    "\n",
    "TensorBoard is a tool for providing the measurements and visualizations needed during the machine learning workflow\n",
    "\n",
    "- https://www.tensorflow.org/tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow                        2.0.0            \n",
      "tensorflow-docs                   0.0.0            \n",
      "tensorflow-estimator              2.0.1            \n",
      "tensorflow-estimator-2.0-preview  2.0.0            \n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip3 install -q tf-nightly-2.0-preview\n",
    "python3 -m pip list | grep tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-nightly-2.0-preview\n",
      "  Using cached https://files.pythonhosted.org/packages/b8/be/e4e2cc0b4896648fe6d5e45dda6d8c3b784823301708cfe4ff96de9e01cf/tf_nightly_2.0_preview-2.0.0.dev20191002-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Processing /home/campos/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc/absl_py-0.8.1-cp36-none-any.whl\n",
      "Collecting google-pasta>=0.1.6\n",
      "  Using cached https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl\n",
      "Collecting keras-applications>=1.0.8\n",
      "  Using cached https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl\n",
      "Collecting wheel>=0.26; python_version >= \"3\"\n",
      "  Using cached https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6/termcolor-1.1.0-cp36-none-any.whl\n",
      "Collecting numpy<2.0,>=1.16.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting protobuf>=3.6.1\n",
      "  Using cached https://files.pythonhosted.org/packages/7c/7a/9dd834766819195bb054ac7d60aba291e6304301a001751dccb4486b444e/protobuf-3.11.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting keras-preprocessing>=1.0.5\n",
      "  Using cached https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd/wrapt-1.11.2-cp36-cp36m-linux_x86_64.whl\n",
      "Collecting six>=1.10.0\n",
      "  Using cached https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd/gast-0.2.2-cp36-none-any.whl\n",
      "Collecting astor>=0.6.0\n",
      "  Using cached https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
      "Processing /home/campos/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833/opt_einsum-3.1.0-cp36-none-any.whl\n",
      "Collecting grpcio>=1.8.6\n",
      "  Using cached https://files.pythonhosted.org/packages/27/28/280658104af767431cf25e397157c4f4a8724a446f9dd5a34dac9812e9c9/grpcio-1.25.0-cp36-cp36m-manylinux2010_x86_64.whl\n",
      "Collecting tensorflow-estimator-2.0-preview\n",
      "  Using cached https://files.pythonhosted.org/packages/db/f5/790508e193121ab301cb40cada7f451c531404051ac9249f21b1f5484450/tensorflow_estimator_2.0_preview-2.0.0-py2.py3-none-any.whl\n",
      "Collecting tb-nightly<2.2.0a0,>=2.1.0a0\n",
      "  Downloading https://files.pythonhosted.org/packages/62/19/58aeae6056ea09eeb697fbb9aa4f42d11f04261c700afc87d57fef5d3474/tb_nightly-2.1.0a20191201-py3-none-any.whl (3.8MB)\n",
      "Collecting h5py\n",
      "  Using cached https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting setuptools\n",
      "  Downloading https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl (583kB)\n",
      "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
      "Collecting markdown>=2.6.8\n",
      "  Using cached https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl\n",
      "Collecting werkzeug>=0.11.15\n",
      "  Using cached https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl\n",
      "Collecting requests<3,>=2.21.0\n",
      "  Using cached https://files.pythonhosted.org/packages/51/bd/23c926cd341ea6b7dd0b2a00aba99ae0f828be89d72b2190f27c11d4b7fb/requests-2.22.0-py2.py3-none-any.whl\n",
      "Collecting google-auth<2,>=1.6.3\n",
      "  Using cached https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
      "Collecting certifi>=2017.4.17\n",
      "  Using cached https://files.pythonhosted.org/packages/b9/63/df50cac98ea0d5b006c55a399c3bf1db9da7b5a24de7890bc9cfd5dd9e99/certifi-2019.11.28-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2\n",
      "  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl\n",
      "Collecting idna<2.9,>=2.5\n",
      "  Using cached https://files.pythonhosted.org/packages/14/2c/cd551d81dbe15200be1cf41cd03869a46fe7226e7450af7a6545bfc474c9/idna-2.8-py2.py3-none-any.whl\n",
      "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
      "  Using cached https://files.pythonhosted.org/packages/b4/40/a9837291310ee1ccc242ceb6ebfd9eb21539649f193a7c8c86ba15b98539/urllib3-1.25.7-py2.py3-none-any.whl\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Using cached https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl\n",
      "Collecting cachetools<3.2,>=2.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
      "Collecting rsa<4.1,>=3.1.4\n",
      "  Using cached https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl\n",
      "Collecting pyasn1<0.5.0,>=0.4.6\n",
      "  Using cached https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl\n",
      "Installing collected packages: six, absl-py, google-pasta, numpy, h5py, keras-applications, wheel, termcolor, setuptools, protobuf, keras-preprocessing, wrapt, gast, astor, opt-einsum, grpcio, tensorflow-estimator-2.0-preview, oauthlib, certifi, chardet, idna, urllib3, requests, requests-oauthlib, pyasn1, pyasn1-modules, cachetools, rsa, google-auth, google-auth-oauthlib, markdown, werkzeug, tb-nightly, tf-nightly-2.0-preview\n",
      "  Found existing installation: six 1.13.0\n",
      "    Uninstalling six-1.13.0:\n",
      "      Successfully uninstalled six-1.13.0\n",
      "  Found existing installation: absl-py 0.8.1\n",
      "    Uninstalling absl-py-0.8.1:\n",
      "      Successfully uninstalled absl-py-0.8.1\n",
      "  Found existing installation: google-pasta 0.1.8\n",
      "    Uninstalling google-pasta-0.1.8:\n",
      "      Successfully uninstalled google-pasta-0.1.8\n",
      "  Found existing installation: numpy 1.17.4\n",
      "    Uninstalling numpy-1.17.4:\n",
      "      Successfully uninstalled numpy-1.17.4\n",
      "  Found existing installation: h5py 2.10.0\n",
      "    Uninstalling h5py-2.10.0:\n",
      "      Successfully uninstalled h5py-2.10.0\n",
      "  Found existing installation: Keras-Applications 1.0.8\n",
      "    Uninstalling Keras-Applications-1.0.8:\n",
      "      Successfully uninstalled Keras-Applications-1.0.8\n",
      "  Found existing installation: wheel 0.33.6\n",
      "    Uninstalling wheel-0.33.6:\n",
      "      Successfully uninstalled wheel-0.33.6\n",
      "  Found existing installation: termcolor 1.1.0\n",
      "    Uninstalling termcolor-1.1.0:\n",
      "      Successfully uninstalled termcolor-1.1.0\n",
      "  Found existing installation: setuptools 42.0.1\n",
      "    Uninstalling setuptools-42.0.1:\n",
      "      Successfully uninstalled setuptools-42.0.1\n",
      "  Found existing installation: protobuf 3.11.0\n",
      "    Uninstalling protobuf-3.11.0:\n",
      "      Successfully uninstalled protobuf-3.11.0\n",
      "  Found existing installation: Keras-Preprocessing 1.1.0\n",
      "    Uninstalling Keras-Preprocessing-1.1.0:\n",
      "      Successfully uninstalled Keras-Preprocessing-1.1.0\n",
      "  Found existing installation: wrapt 1.11.2\n",
      "    Uninstalling wrapt-1.11.2:\n",
      "      Successfully uninstalled wrapt-1.11.2\n",
      "  Found existing installation: gast 0.2.2\n",
      "    Uninstalling gast-0.2.2:\n",
      "      Successfully uninstalled gast-0.2.2\n",
      "  Found existing installation: astor 0.8.0\n",
      "    Uninstalling astor-0.8.0:\n",
      "      Successfully uninstalled astor-0.8.0\n",
      "  Found existing installation: opt-einsum 3.1.0\n",
      "    Uninstalling opt-einsum-3.1.0:\n",
      "      Successfully uninstalled opt-einsum-3.1.0\n",
      "  Found existing installation: grpcio 1.25.0\n",
      "    Uninstalling grpcio-1.25.0:\n",
      "      Successfully uninstalled grpcio-1.25.0\n",
      "  Found existing installation: tensorflow-estimator-2.0-preview 2.0.0\n",
      "    Uninstalling tensorflow-estimator-2.0-preview-2.0.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.0-preview-2.0.0\n",
      "  Found existing installation: oauthlib 3.1.0\n",
      "    Uninstalling oauthlib-3.1.0:\n",
      "      Successfully uninstalled oauthlib-3.1.0\n",
      "  Found existing installation: certifi 2019.11.28\n",
      "    Uninstalling certifi-2019.11.28:\n",
      "      Successfully uninstalled certifi-2019.11.28\n",
      "  Found existing installation: chardet 3.0.4\n",
      "    Uninstalling chardet-3.0.4:\n",
      "      Successfully uninstalled chardet-3.0.4\n",
      "  Found existing installation: idna 2.8\n",
      "    Uninstalling idna-2.8:\n",
      "      Successfully uninstalled idna-2.8\n",
      "  Found existing installation: urllib3 1.25.7\n",
      "    Uninstalling urllib3-1.25.7:\n",
      "      Successfully uninstalled urllib3-1.25.7\n",
      "  Found existing installation: requests 2.22.0\n",
      "    Uninstalling requests-2.22.0:\n",
      "      Successfully uninstalled requests-2.22.0\n",
      "  Found existing installation: requests-oauthlib 1.3.0\n",
      "    Uninstalling requests-oauthlib-1.3.0:\n",
      "      Successfully uninstalled requests-oauthlib-1.3.0\n",
      "  Found existing installation: pyasn1 0.4.8\n",
      "    Uninstalling pyasn1-0.4.8:\n",
      "      Successfully uninstalled pyasn1-0.4.8\n",
      "  Found existing installation: pyasn1-modules 0.2.7\n",
      "    Uninstalling pyasn1-modules-0.2.7:\n",
      "      Successfully uninstalled pyasn1-modules-0.2.7\n",
      "  Found existing installation: cachetools 3.1.1\n",
      "    Uninstalling cachetools-3.1.1:\n",
      "      Successfully uninstalled cachetools-3.1.1\n",
      "  Found existing installation: rsa 4.0\n",
      "    Uninstalling rsa-4.0:\n",
      "      Successfully uninstalled rsa-4.0\n",
      "  Found existing installation: google-auth 1.7.1\n",
      "    Uninstalling google-auth-1.7.1:\n",
      "      Successfully uninstalled google-auth-1.7.1\n",
      "  Found existing installation: google-auth-oauthlib 0.4.1\n",
      "    Uninstalling google-auth-oauthlib-0.4.1:\n",
      "      Successfully uninstalled google-auth-oauthlib-0.4.1\n",
      "  Found existing installation: Markdown 3.1.1\n",
      "    Uninstalling Markdown-3.1.1:\n",
      "      Successfully uninstalled Markdown-3.1.1\n",
      "  Found existing installation: Werkzeug 0.16.0\n",
      "    Uninstalling Werkzeug-0.16.0:\n",
      "      Successfully uninstalled Werkzeug-0.16.0\n",
      "  Found existing installation: tb-nightly 2.1.0a20191130\n",
      "    Uninstalling tb-nightly-2.1.0a20191130:\n",
      "      Successfully uninstalled tb-nightly-2.1.0a20191130\n",
      "  Found existing installation: tf-nightly-2.0-preview 2.0.0.dev20191002\n",
      "    Uninstalling tf-nightly-2.0-preview-2.0.0.dev20191002:\n",
      "      Successfully uninstalled tf-nightly-2.0-preview-2.0.0.dev20191002\n",
      "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 certifi-2019.11.28 chardet-3.0.4 gast-0.2.2 google-auth-1.7.1 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 idna-2.8 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.17.4 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.0 pyasn1-0.4.8 pyasn1-modules-0.2.7 requests-2.22.0 requests-oauthlib-1.3.0 rsa-4.0 setuptools-42.0.2 six-1.13.0 tb-nightly-2.1.0a20191201 tensorflow-estimator-2.0-preview-2.0.0 termcolor-1.1.0 tf-nightly-2.0-preview-2.0.0.dev20191002 urllib3-1.25.7 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Skipping tensorboard as it is not installed.\n",
      "ERROR: tensorflow 2.0.0 requires tensorboard<2.1.0,>=2.0.0, which is not installed.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "pip uninstall -y tensorboard\n",
    "pip install --force-reinstall tf-nightly-2.0-preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime, os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare Log Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "\n",
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download the FashionMNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fashion_mnist = tf.keras.datasets.fashion_mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "      return tf.keras.models.Sequential([\n",
    "                                        tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "                                        tf.keras.layers.Dense(512, activation='relu'),\n",
    "                                        tf.keras.layers.Dropout(0.2),\n",
    "                                        tf.keras.layers.Dense(10, activation='softmax')\n",
    "                                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model using Keras and the TensorBoard callback\n",
    "Ao treinar com o `model.fit()` de Keras e adicionar o retorno `keras.callback.TensorBoard()` garante que os logs sejam criados e armazenados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    model = create_model()\n",
    "    model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "    logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "    model.fit(x=x_train, \n",
    "            y=y_train, \n",
    "            epochs=5, \n",
    "            validation_data=(x_test, y_test), \n",
    "            callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 8s 127us/sample - loss: 0.4996 - accuracy: 0.8197 - val_loss: 0.4786 - val_accuracy: 0.8330\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 7s 123us/sample - loss: 0.3860 - accuracy: 0.8580 - val_loss: 0.4004 - val_accuracy: 0.8545\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 7s 120us/sample - loss: 0.3500 - accuracy: 0.8709 - val_loss: 0.3819 - val_accuracy: 0.8620\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 7s 114us/sample - loss: 0.3299 - accuracy: 0.8770 - val_loss: 0.3699 - val_accuracy: 0.8670\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 7s 115us/sample - loss: 0.3129 - accuracy: 0.8835 - val_loss: 0.3755 - val_accuracy: 0.8598\n"
     ]
    }
   ],
   "source": [
    "train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start TensorBoard\n",
    "\n",
    "- tabs\n",
    "  - Scalars: alteração da loss function\n",
    "  - Graphs: mostra o modelo\n",
    "  - Dstribuitions e Histograms: mostra a distribuição de um tensor através do tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6007 (pid 20186), started 11:47:00 ago. (Use '!kill 20186' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-90a73e46fd6c87d4\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-90a73e46fd6c87d4\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6007;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras to TensorFlow\n",
    "\n",
    "https://www.dlology.com/blog/how-to-convert-trained-keras-model-to-tensorflow-and-make-prediction/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
