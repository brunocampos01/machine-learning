{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Otimization for Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Cost Function\n",
    "  - Mean Square Error\n",
    "  - Mean Absolute Error\n",
    "  - Cross Entropy Error\n",
    "- Backpropagation Algorithm\n",
    "  - Feedforward\n",
    "  - Backpropagation\n",
    "- Stocastic Gradient Descent\n",
    "  - Stocastic\n",
    "  - Mini-lote\n",
    "- Local Minimum Problem\n",
    "- Overfit and Underfit\n",
    "- Undertanding Learning Rate\n",
    "- Dropout\n",
    "- Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### **Cost (Loss) Function**\n",
    "- Tem por objetivo encontrar valores de **W** e **b** que minimizam o erro.\n",
    "- Não há mudanças na forma de calcular o custo do modelo linear\n",
    "  \n",
    "<img src=\"reports/error_formula_linear_model.png\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "- Para calcular a quantidade de error por hipótese é usado:\n",
    "  - MSE (Mean Square Error)\n",
    "  - MAE (Mean Absolute Error)\n",
    "  - CEE (Cross Entropy Error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "#### Mean Square Error (MSE/ L2 Loss)\n",
    "- Usado para classificação linear multipla.\n",
    "- **MSE não pode ser usado para classifcação binária.**.\n",
    "- Por dado\n",
    "\\begin{align*}\n",
    "  & SE = (y_i - (m x_i + b))^2\n",
    "\\end{align*}\n",
    "- Média\n",
    "\\begin{align*}\n",
    "  & MSE = \\frac{1}{N} \\sum_{i=0}^n(y_i - (m x_i + b))^2\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "\n",
    "\n",
    "y_true = [1, 1, 2, 2, 4]\n",
    "y_pred = [0.6, 1.29, 1.99, 2.69, 3.4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21606"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_square_error_np(y_true: list, y_pred: list):\n",
    "    \"\"\"\n",
    "    :Params:\n",
    "        Y_true: list of true values    \n",
    "        Y_pred: list of predicted values\n",
    "    \n",
    "    :Returns:\n",
    "        mean square error loss\n",
    "    \"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "     \n",
    "    return ((y_true - y_pred)**2).mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21606"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_square_error_np(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean Absolute Error (MAE/ L1 loss)\n",
    "- Calcula a **diferença absoluta** entre os valores estimados e valores reais.\n",
    "- Math\n",
    "\n",
    "\\begin{align*}\n",
    "  & MAE = \\sum_{i=0}^n|y_i - (m x_i + b)|\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mae(true, pred):\n",
    "    \"\"\"\n",
    "    true: array of true values    \n",
    "    pred: array of predicted values\n",
    "    \n",
    "    returns: mean absolute error loss\n",
    "    \"\"\"\n",
    "    \n",
    "    return np.sum(np.abs(true - pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MSE vs. MAE (L2 loss vs L1 loss)\n",
    "- Um grande problema no uso da função loss com MAE é que seu gradiente é o mesmo, o que significa que o gradiente será grande mesmo para pequenos valores de perda. Isso não é bom para aprender.\n",
    "- O MSE se comporta bem nesse caso e convergirá mesmo com uma taxa de aprendizado fixa. O gradiente de perda de MSE é alto para valores de perda maiores e diminui à medida que a perda se aproxima de 0, tornando-o mais preciso no final do treinamento (veja a figura abaixo).\n",
    "\n",
    "<img src=\"reports/mse_mae.png\" align=\"center\" height=auto width=90%/>\n",
    "\n",
    "- **Use MSE para por default mas se houver outliers use MAE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "#### Cross Entropy Error (log loss)\n",
    "- Entropia é um medida da incerteza associado a uma determinada distribuição.\n",
    "- Calcula a probabilidade de um valor predito ser diferente do valor real. \n",
    "- Usado para **classificação binária**.\n",
    "- Math\n",
    "\\begin{align*}\n",
    " CEE = -{(y\\log(hyp) + (1 - y)\\log(1 - hyp))}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Example\n",
    "  - O eixo `x` são as features\n",
    "  - A cor de cada bola é p `label`\n",
    "<img src=\"reports/linw.png\" align=\"center\" height=auto width=90%/>\n",
    "\n",
    "Este é um problema de classficação binária. Então podemos perguntar:\n",
    "- `Qual a probabilidade de um ponto ser verde?`\n",
    "- A partir disso, temos\n",
    "  - verde = 1\n",
    "  - vermelho = 0\n",
    "\n",
    "- Depois de prevermos a classificação de cada ponto, como podemos avaliar quão boas (ou ruins) são as probabilidades previstas? Este é todo o objetivo da loss function ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "\n",
    "x = np.array([-2.2, -1.4, -.8, .2, .4, .8, 1.2, 2.2, 2.9, 4.6])\n",
    "y_true = np.array([0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n",
    "\n",
    "y_pred = [0.19, 0.33, 0.47, 0.7, 0.74, 0.81, 0.86, 0.94, 0.97, 0.99]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3335227947407202"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = log_loss(y, y_pred)\n",
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_error(y_true, y_pred): \n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    \n",
    "    return (-(y_true) * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.029511485707022563"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy_error(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Backpropagation Algoritm**\n",
    "_Using a model's outputs to train in to do even better._\n",
    "\n",
    "**A retropropagação é o mecanismo central pelo qual as redes neurais aprendem.** \n",
    "\n",
    "<img src=\"reports/Backpropagation GIF-source.gif\" align=\"center\" height=auto width=50%/>\n",
    "\n",
    "\n",
    "Pode ser visto como o descent gradient.\n",
    "Este é a estratégia de otimização mais usada em neural networks.\n",
    "\n",
    "\n",
    "É um Algoritmo feito por 2 partes:\n",
    "- Feedforward, que é o processo que neural networks usam para identificar erros de predição. \n",
    "- Backpropation, que é usar o descent gradient para atualizar os pesos **w**.\n",
    "\n",
    "### Steps\n",
    "**Feedforward**\n",
    "1. Realizar uma operação de feedforward (propagação) com os pesos **w** aleatórios.\n",
    "2. Comparar a saída do modelo com a saída desejada.\n",
    "3. Calcular o erro.\n",
    "\n",
    "<img src=\"reports/feedfoward_complete.gif\" align=\"center\" height=auto width=60%/>\n",
    "\n",
    "**Backpropagation**\n",
    "4. Executar a operação de feedforward de forma reversa (backpropagation) para espalhar o erro para cada um dos pesos.\n",
    "5. Usar isso para atualizar os pesos e conseguir um modelo mais adequado.\n",
    "6. Continuar este processo até que tenhamos um modelo que funcione bem.\n",
    "\n",
    "<img src=\"reports/backpropagation.gif\" align=\"center\" height=auto width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "### Running\n",
    "**Feedforward**\n",
    "\n",
    "Quando há uma classificação errada o modelo \"pergunta\" ao dado:\n",
    "```\n",
    "O que posso fazer para melhorar a sua classificação?\n",
    "```\n",
    "\n",
    "<img src=\"reports/feed.png\" align=\"center\" height=auto width=70%/>\n",
    "\n",
    "O dado responderá:\n",
    "```\n",
    "Quero que a região azul se aproxime de mim !\n",
    "O modelo de cima esta me classificando errado\n",
    "O modelo de baixo esta me classificando corretamente\n",
    "```\n",
    "\n",
    "<img src=\"reports/feed_aws.png\" align=\"center\" height=auto width=70%/>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "\n",
    "**Backpropagation**\n",
    "Então o que precisamos é que o modelo de baixo tenha maior relevância na neural network. Para isso é necessário atualizar os pesos **w** de cada modelo\n",
    "\n",
    "<img src=\"reports/feedforwad.gif\" align=\"center\" height=auto width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## Época\n",
    "- No contexto de treinamento de um modelo, época é um termo usado para se referir a uma iteração em que o modelo vê todo o treinamento definido para atualizar seus pesos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ADD():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        return x1 + x2\n",
    "\n",
    "    def backward(self, d):\n",
    "        dx = d * 1\n",
    "        dy = d * 1\n",
    "        return dx, dy\n",
    "\n",
    "    \n",
    "class MUL():\n",
    "    def __init__(self):\n",
    "        self.x1 = None\n",
    "        self.x2 = None \n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        return x1 * x2\n",
    "\n",
    "    def backward(self, d):\n",
    "        dx1 = d * self.x2\n",
    "        dx2 = d * self.x1\n",
    "        return dx1, dx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y: 13\n",
      "dCOST/dX1: 5\n",
      "dCOST/dX2: 2\n",
      "dCOST/dC: 1\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "x1 = 2\n",
    "x2 = 5\n",
    "C = 3\n",
    "\n",
    "# Nodes\n",
    "mul = MUL()\n",
    "add = ADD()\n",
    "\n",
    "# Forward\n",
    "s1 = mul.forward(x1, x2)\n",
    "s2 = C\n",
    "y = add.forward(s1, s2)\n",
    "\n",
    "# Backward\n",
    "# Let's assume dCOST/dY is 1\n",
    "ds1, ds2 = add.backward(1)\n",
    "dc = ds2\n",
    "dx1, dx2 = mul.backward(ds1)\n",
    "\n",
    "print(\"Y: {0}\".format(y))\n",
    "print(\"dCOST/dX1: {0}\".format(dx1))\n",
    "print(\"dCOST/dX2: {0}\".format(dx2))\n",
    "print(\"dCOST/dC: {0}\".format(dc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Gradient Descent**\n",
    "\n",
    "### Stochastic Gradient Descent (\"on-line\")\n",
    "- Gradiente é uma função vetorial que representa a inclinação e sentido da tangente na função cost.\n",
    "- O símbolo ∇ (nabla) representa o gradiente.\n",
    "- Trajetória estocástica permite escapar de um míminos locais.\n",
    "\n",
    "#### Running\n",
    "A descida do gradiente estocástico (SGD) **realiza uma atualização de parâmetro para cada exemplo de treinamento**. Portanto, em vez de repetir cada observação, basta uma para executar a atualização do parâmetro. O SGD geralmente é mais rápido que a descida do gradiente em lote, mas suas atualizações frequentes causam uma variação maior na taxa de erros,\n",
    "\n",
    "- alta variação daa funcao loss\n",
    "\n",
    "<img src=\"reports/Stogra.png\" align=\"center\" height=auto width=70%/>\n",
    "\n",
    "### Gradient Descent Mini-lote \n",
    "_É melhor dar pequenos passos imprecisos do que dar um passo certeiro !_\n",
    "\n",
    "- A descida do gradiente de mini-lote executa uma atualização para um lote de observações.\n",
    "- Durante a fase de training, a atualização de pesos geralmente não se baseia em todo o conjunto de treinamento de uma só vez devido a complexidades de computação. Em vez disso, **a etapa de atualização é realizada em mini-lotes**, onde o número de pontos de dados em um lote é um hiperparâmetro que podemos ajustar.\n",
    "- Convergência mais rápida, especialmente com grandes quantidade de dados ou dados redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Descent with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'random_normal'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-168-8f25c1ba15f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"weight\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;31m# [1] means its rank is 1, and the number of data is 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'random_normal'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# y = x\n",
    "x_data = [1,2,3]\n",
    "y_data = [1,2,3]\n",
    "\n",
    "# Weight\n",
    "W = tf.Variable(tf.random_normal([1]), name=\"weight\")\n",
    "# [1] means its rank is 1, and the number of data is 1.\n",
    "\n",
    "# Placeholder for X & Y\n",
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "# Simplified hypothesis\n",
    "hypothesis = X * W\n",
    "\n",
    "# Cost function: Mean Square Error\n",
    "cost = tf.reduce_sum(tf.square(hypothesis - Y))\n",
    "\n",
    "# Minimize error\n",
    "# Gradient descent using derivative\n",
    "# W -= learning_rate * dereivative\n",
    "learning_rate = 0.01\n",
    "gradient = tf.reduce_mean((W * X - Y) * X)\n",
    "descent = W - learning_rate * gradient\n",
    "update = W.assign(descent)\n",
    "# It can be relpaced by\n",
    "# optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "# train = optimizer.minimize(cost)\n",
    "\n",
    "# Launch the graph in a session\n",
    "sess = tf.Session()\n",
    "# Initializes global variables in the graph\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# For graph\n",
    "steps = []\n",
    "outputs = {\"cost\" : [], \"weight\" : []}\n",
    "\n",
    "# Train\n",
    "for step in range(51):\n",
    "    # W is a variable, update is an operation to update W\n",
    "    # After update, W will be updated.\n",
    "    sess.run(update, feed_dict={X: x_data,Y: y_data})\n",
    "\n",
    "    _cost = sess.run(cost, feed_dict={X: x_data, Y: y_data})\n",
    "    _W = sess.run(W)\n",
    "\n",
    "    steps.append(step)\n",
    "    outputs[\"cost\"].append(_cost)\n",
    "    outputs[\"weight\"].append(_W)\n",
    "\n",
    "    if step in (1, 10, 20, 30, 40, 50):\n",
    "        print(\"Step: {0:4d}, Cost: {1:13.10f}, Weight: {2:13.10f}\".\\\n",
    "              format(step, _cost, _weight[0]))\n",
    "\n",
    "# Draw graph\n",
    "for k, v in outputs.items():\n",
    "    plt.plot(steps, v)\n",
    "    plt.title(k)\n",
    "    plt.xlabel(\"step\")\n",
    "    plt.ylabel(k)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Local Minimum Problem**\n",
    "\n",
    "<img src=\"reports/gradient_descent_local_min.png\" align=\"center\" height=auto width=100%/>\n",
    "\n",
    "O gradient descent nos dá alterações muuuuito pequenas. Isso se torna um problema pois pode cair em mínimos locais. É neste momento que temos que mudar a activate function !\n",
    "\n",
    "<br/>\n",
    "\n",
    "### Random Restart\n",
    "Para solucionar este problema começamos a calcular o gradient dscent em ponto aleatórios\n",
    "\n",
    "<img src=\"reports/ramdom_restart.gif\" align=\"center\" height=auto width=100%/>\n",
    "\n",
    "Isso aumenta a probabilidade de encontrar o mínimo local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Undertanding Learning Rate**\n",
    "Valor muito alto de learning rate faz as epochs serem rápidas mas o modelo perderá o minímo local o tornando caótico.\n",
    "\n",
    "<img src=\"reports/learning_rate.png\" align=\"rightr\" height=auto width=80%/>\n",
    "\n",
    "Um bom valor em learning rate faz com que o modelo diminua quando se aproxima do mínimo local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Underfit and Overfit in Neural Networks**\n",
    "\n",
    "<img src=\"reports/under_overfit.png\" align=\"center\" height=auto width=85%/>\n",
    "\n",
    "Se juntarmos somente os pontos de cada epoch podemos notar qual é o melhor resultado\n",
    "\n",
    "<img src=\"reports/points.png\" align=\"center\" height=auto width=95%/>\n",
    "\n",
    "#### Model Complexity\n",
    "\n",
    "<img src=\"reports/model_complexity.png\" align=\"center\" height=auto width=95%/>\n",
    "\n",
    "Para encontrar o ponto ideal é necessário usar o algoritmo **early stopping** gradient descent até que ele começe a aumentar.\n",
    "\n",
    "### Most Common Ways to Prevent Overfitting in Neural Networks\n",
    "- Obetermais dados de treinamento.\n",
    "- Reduzir a capadidade da rede.\n",
    "- Adicionar weight de regularização.\n",
    "- Adicionar dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Regularization**\n",
    "Uma maneira comum de mitigar o overfit é restringir a complexidade de uma rede, forçando seus pesos apenas a aceitar valores pequenos, o que torna a distribuição dos valores de peso mais \"regular\". Isso é chamado de **regularização de peso é feito adicionando à função de loss de uma rede, um custo**. Há 2 tipos de custos:\n",
    "- Regularização de L1: em que o custo adicionado é proporcional ao valor absoluto dos coeficientes de pesos.\n",
    "- Regularização de L2: em que o custo adicionado é proporcional ao quadrado do valor dos coeficientes de pesos.\n",
    "\n",
    "#### NOTES\n",
    "- **A regularização L1 empurra pesos para exatamente zero**, incentivando um modelo esparso.\n",
    "- **A regularização de L2 penalizará os parâmetros de pesos sem torná-los escassos**, pois a penalidade é zero para pesos pequenos. uma razão pela qual L2 é mais comum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0-dev20191002\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.sequential.Sequential at 0x7f15042369b0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "print(tf.__version__)\n",
    "\n",
    "\n",
    "FEATURES = 28\n",
    "\n",
    "combined_model = tf.keras.Sequential([\n",
    "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                 activation='elu', input_shape=(FEATURES,)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                 activation='elu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                 activation='elu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, kernel_regularizer=regularizers.l2(0.0001),\n",
    "                 activation='elu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "combined_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quiz\n",
    "\n",
    "<img src=\"reports/quiz_overfit.png\" align=\"center\" height=auto width=75%/>\n",
    "\n",
    "A predição são sigmoide\n",
    "\n",
    "<img src=\"reports/quis_2.png\" align=\"center\" height=auto width=75%/>\n",
    "\n",
    "O modelo 2 pode até apresentar melhores resultados mas não generaliza tão bem quanto o primiero.\n",
    "\n",
    "<img src=\"reports/large_coefficients_overfitting.png\" align=\"center\" height=auto width=75%/>\n",
    "\n",
    "<img src=\"reports/regularization_penalize.png\" align=\"center\" height=auto width=75%/>\n",
    "\n",
    "<img src=\"reports/l1_l2.png\" align=\"center\" height=auto width=75%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Dropout**\n",
    "As vezes uma parte da neural network tem muito peso e acaba dominando o training.\n",
    "\n",
    "<img src=\"reports/drop_out.png\" align=\"center\" height=auto width=95%/>\n",
    "\n",
    "Uma solução para isso é desligar alguns perceptrons aleatóriamente. Para isso damos uma probabilidade em cada epoch de um nodo ser desligado \n",
    "\n",
    "<img src=\"reports/dropout.gif\" align=\"center\" height=auto width=95%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br/>\n",
    "\n",
    "## **Keras Optimazation**\n",
    "Existem vários otimizadores no Keras, que encorajamos que você explore mais a fundo, neste link ou nesta excelente postagem de blog. Estes otimizadores usam uma combinação dos truques acima, além de outros. Alguns dos mais comuns são:\n",
    "\n",
    "### SGD\n",
    "Este é o gradiente descendente estocástico. Ele usa os seguintes parâmetros:\n",
    "\n",
    "- Taxa de aprendizagem.\n",
    "- Momentum (que usa a média ponderada dos passos anteriores para conseguir um impulso para superar flutuações e o treinamento não ficar preso em mínimos locais).\n",
    "- Momentum de Nesterov (que reduz a velocidade do gradiente quando se está mais próximo da solução).\n",
    "\n",
    "### Adam\n",
    "Adam (Adaptive Moment Estimation ou estimação adaptativa de momento) usa um decaimento exponencial mais complicado que consiste em não só considerar a média (primeiro momento), mas também a variância (segundo momento) dos últimos passos.\n",
    "\n",
    "## RMSProp\n",
    "RMSProp (RMS é a sigla em inglês para raiz quadrada do erro médio) reduz a taxa de aprendizagem ao dividi-la por uma média de gradientes elevados ao quadrado que decai exponencialmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### References\n",
    "- [1] https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
