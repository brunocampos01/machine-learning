{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Load Data\n",
    "\n",
    "There are many ways to get a dataset like:\n",
    "- API\n",
    "- Scrapping\n",
    "- Download file\n",
    "\n",
    "\n",
    "## Files\n",
    "\n",
    "To keep order, all scripts to get data, must stay in `src` directory.\n",
    "\n",
    "```\n",
    "├── src                <- Source code for use in this project.\n",
    "    ├── __init__.py    <- Makes src a Python module\n",
    "    │\n",
    "    ├── make_dataset.py <- Scripts to download or generate data\n",
    "\n",
    "```\n",
    "\n",
    "### Download files\n",
    "- Must save script in `src/make_dataset.py` \n",
    "- Case orther notebook need import, do:<br/>\n",
    "`from <package>.<module> import <class>`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data analysis and data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Machine learning\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "# Metrics\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# Dataset\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Other\n",
    "from IPython.display import Image\n",
    "import configparser\n",
    "import subprocess\n",
    "import warnings\n",
    "import pprint\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Cell Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guarantees visualization inside the jupyter\n",
    "%matplotlib inline\n",
    "\n",
    "# OPTIONAL: Load the \"autoreload\" extension so that code can change\n",
    "%load_ext autoreload\n",
    "\n",
    "# Format the data os all table (float_format 3)\n",
    "pd.set_option('display.float_format', '{:.6}'.format)\n",
    "\n",
    "# Print xxxx rows and columns\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Pretty print\n",
    "pp = pprint.PrettyPrinter(indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Principal Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_directory_work(end_directory: str='notebooks'):\n",
    "    # Current path\n",
    "    curr_dir = os.path.dirname (os.path.realpath (\"__file__\")) \n",
    "    \n",
    "    if curr_dir.endswith(end_directory):\n",
    "        os.chdir('..')\n",
    "        return curr_dir\n",
    "    \n",
    "    return f'Current working directory: {curr_dir}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/campos/projetos/artificial_inteligence/data-science/flow_analysis/notebooks'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prepare_directory_work(end_directory='notebooks')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### API\n",
    "\n",
    "It's very important with process be automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{   'Realtime Currency Exchange Rate': {   '1. From_Currency Code': 'USD',\n",
      "                                           '2. From_Currency Name': 'United '\n",
      "                                                                    'States '\n",
      "                                                                    'Dollar',\n",
      "                                           '3. To_Currency Code': 'BRL',\n",
      "                                           '4. To_Currency Name': 'Brazilian '\n",
      "                                                                  'Real',\n",
      "                                           '5. Exchange Rate': '3.76610000',\n",
      "                                           '6. Last Refreshed': '2019-07-10 '\n",
      "                                                                '16:06:13',\n",
      "                                           '7. Time Zone': 'UTC',\n",
      "                                           '8. Bid Price': '-',\n",
      "                                           '9. Ask Price': '-'}}\n",
      "Data Storaged!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "\n",
    "url = 'https://www.alphavantage.co/query?function=CURRENCY_EXCHANGE_RATE&from_currency=USD&to_currency=BRL&apikey=O3MU8PIQJXVFJ3F3'\n",
    "response = requests.get(url)\n",
    "\n",
    "# get data\n",
    "data_reaktime = response.json()\n",
    "pp.pprint(data_reaktime)\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "now = str(now.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "# save\n",
    "with open('data/dumps/' + 'USD-BRL-' + now + '.json', mode='w+') as writer:\n",
    "    writer.write(json.dumps(datas))\n",
    "    print('Data Storaged!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping page\n",
    " It's very important with process be automated.\n",
    "\n",
    "- Examples\n",
    "  - Download gastos públicos senadores\n",
    "  - Download stock price\n",
    "\n",
    "#### Gastos públicos senadores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Install beatiful\n",
    "`pip install beautifulsoup4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Site to get csv\n",
    "url = 'https://www12.senado.leg.br/transparencia/dados-abertos-transparencia/dados-abertos-ceaps'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from <package>.<module> import <class>\n",
    "from src.dump_data.dump_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Try analysing page ...\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2019.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2018.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2017.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2016.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2015.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2014.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2013.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2012.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2011.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2010.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2009.csv\n",
      "http://www.senado.gov.br/transparencia/LAI/verba/2008.csv\n",
      "data/dumps/2019.csv downloaded!\n",
      "data/dumps/2018.csv downloaded!\n",
      "data/dumps/2017.csv downloaded!\n",
      "data/dumps/2016.csv downloaded!\n",
      "data/dumps/2015.csv downloaded!\n",
      "data/dumps/2014.csv downloaded!\n",
      "data/dumps/2013.csv downloaded!\n",
      "data/dumps/2012.csv downloaded!\n",
      "data/dumps/2011.csv downloaded!\n",
      "data/dumps/2010.csv downloaded!\n",
      "data/dumps/2009.csv downloaded!\n",
      "data/dumps/2008.csv downloaded!\n"
     ]
    }
   ],
   "source": [
    "dump_file_csv(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "- Using `open`\n",
    "- Using pandas `read_csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedReader name='data/raw/enrollments.csv'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "open('data/raw/enrollments.csv', 'rb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenization took: 1.38 ms\n",
      "Type conversion took: 2.01 ms\n",
      "Parser memory cleanup took: 0.01 ms\n",
      "CPU times: user 9.94 ms, sys: 6 µs, total: 9.94 ms\n",
      "Wall time: 8.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dataframe_name = pd.read_csv('data/raw/enrollments.csv', \n",
    "                            encoding='utf8',\n",
    "                            delimiter=',',\n",
    "                            verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
